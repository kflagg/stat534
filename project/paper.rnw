\documentclass[11pt]{article}
\usepackage{fullpage,graphicx,float,amsmath,enumitem,fancyhdr,hyperref}

\setlist{parsep=5.5pt}
\setlength{\parindent}{0pt}
\setlength{\parskip}{5.5pt}

\usepackage[backend=bibtex,style=authoryear,citestyle=authoryear-comp]{biblatex}
\addbibresource{references.bib}

\newcommand\assignment{Stat 534 Project: \\
Extrapolation from Poisson Process Intensity Surface Models}
\newcommand\myname{Kenny Flagg}
\newcommand\duedate{\today}

\pagestyle{fancy}
\lhead{Stat 534 Project}
\chead{\duedate}
\rhead{\myname}
\setlength{\headheight}{18pt}
\setlength{\headsep}{2pt}

\title{\assignment}
\author{\myname}
\date{\duedate}

\begin{document}
\maketitle

<<setup, echo = FALSE, message = FALSE, cache = FALSE>>=
library(knitr)
library(extrafont)
opts_chunk$set(echo = FALSE, comment = NA, message = FALSE,
               fig.path = 'paper_figure/', cache.path = 'paper_cache/',
               show.signif.stars = FALSE,
               fig.align = 'center', fig.width = 6.5, fig.height = 3,
               fig.pos = 'H', size = 'footnotesize', dev = 'pdf',
               dev.args = list(family = 'CM Roman', pointsize = 11))
knit_theme$set('print')

library(xtable)
options(xtable.table.placement = 'H', width = 80, scipen = 2,
        xtable.sanitize.rownames.function = function(x){return(x)},
        show.signif.stars = FALSE)

library(spatstat)

set.seed(83534)
@


\section{Introduction}

One little-studied application of inhomogeneous point process intensity
estimation is the use of an intensity surface estimated from events in a
subregion to predict the intensity over the entire region of interest. This
procedure would be relevant whenver it is known or suspected that some type of
plant, animal, or other item occurs in the region, and the goal of the
analysis is to map the trend in where these tend to be located rather than
estimate parameters of some process at work across hypothetical replicates of
similar regions. It may be prohibitively expensive or difficult to observe all
events over the entire region, so a sample of subregions is taken. For
example, conservationists want to study the spatial distribution of an
endangered plant across a large region of thick jungle so that they can
establish a preserve where the plant is protected. They cannot search the
entire jungle, so they take a simple random sample of quadrats and record the
locations of the plants in those quadrats. They will then want to fit a model
describing the trends in intensity of these plants extrapolated over the
entire jungle. In this setting, the objective is to map the realized spatial
intensity of the plant over this jungle so that these plants can be protected,
not to estimate parameters of the process that arranges plants of this species
at jungles like this one.

Another situation where it is useful to extrapolate point pattern intensity
outside of the observed region is in mapping subsurface geomagnetic anomalies,
such as the munitions debris found at former military test ranges. This is
frequently done in the early stages of an unexploded ordnance (UXO)
remediation, where the intensity surface of inert munitions fragments is
used to identify the locations of targets so that the search for UXO can be
focused on the sections of the site most likely to contain it. The anomalies
are only observed when detection equipment passes directly over them, but the
project leaders are concerened with finding UXO and do not want to waste
resources finding every inert fragment that could be found by metal detectors.
The most common data collection method is to take a systematic sample of
straight-line transects and observe anomalies in rectangular regions centered
along the transects. Frequently, moving averages of the intensity are computed
in circular windows and an intensity map is produced using ordinary kriging to
predict the intensity in a grid of these windows. There are several problems
with this approach: it assumes stationarity when the moving averages are
believed to be non-stationary, it ignores the point process nature of the
data, and it is very sensitive to the window size~\parencite{vspguide,wp}. In
this project, I explore the use of polynomial trend surface models for the
log-intensity at a simulated UXO site.


\section{Surface Fitting}

It is theoretically possible to use maximum likelihood or maximum
pseudo-likelihood methods to fit trend surface models or regression models
(with covariates) for the intensity of an inhomogeneous point process, but
these are not widely used because, in the most general cases, the problems
are ``notoriously intractable''~\parencite{digglebook}. However, for spatial
Poisson processes, trend surface models are tenable with the help of some
numerical methods.

The log-likelihood of an unmarked Poisson process on a region \(D\) with
intensity \(\lambda(\mathbf{s})\) is found by conditioning on the number of
events in the following manner. The number of events in \(D\) follows a
Poisson distribution with mean \(\mu=\int_{D}\lambda(\mathbf{s})d\mathbf{s}\).
Given that \(n\) events occured, their locations \(\mathbf{s}_{1},\dots,
\mathbf{s}_{n}\) are independent and identically distributed with density
\(\lambda(\mathbf{s})/\mu\). Then the log-likelihood of the intensity is
\begin{align*}
\ell(\lambda) &= \left(-\mu + n\log(\mu) - \log(n!)\right)
+ \left(\sum_{i=1}^{n}\left[\log\left(\lambda(\mathbf{s}_{i})\right)
- \log(\mu)\right]\right) \\
&= \sum_{i=1}^{n}\log\left(\lambda(\mathbf{s}_{i})\right)
-\int_{D}\lambda(\mathbf{s})d\mathbf{s} - \log(n!).
\end{align*}
A natural way to model the intensity is to define a log-linear model
\begin{equation*}
\log(\lambda(\mathbf{s})) = \mathbf{x}(\mathbf{s})^{T}\boldsymbol{\beta}
\end{equation*}
where \(\mathbf{x}(\mathbf{s})\) can, in principle, include functions of the
spatial coordinates and also covariates. Unfortunately, the likelihood becomes
\begin{equation*}
\sum_{i=1}^{n}\mathbf{x}(\mathbf{s})^{T}\boldsymbol{\beta}
-\int_{D}\exp\left(\mathbf{x}(\mathbf{s})^{T}
\boldsymbol{\beta}\right)d\mathbf{s} - \log(n!)
\end{equation*}
so \(\mathbf{x}(\mathbf{s})\) must be known (or predicted) either across the
entire region \(D\) or at enough locations to approximate the integral
numerically. Thus, covariates require some extra data collection or modeling
effort to incorporate, but trend surfaces are feasible.

\textcite{bermanturner} proposed a practical method for fitting these models
with generalized linear models software using quadratic approximations to the
likelihood, even generalizing to other link functions besides the log link.
Their method is based on partitioning \(D\) such that each subset in the
partition contains at most one event, and then using a binomial or Poission
distribution for the count of events in each subset. This was followed up by
\textcite{baddeleycoeurjolly14}, who developed a logistic regression-based
approach that avoids the quadratic approximation, thereby reducing bias in the
coefficient estimates. Both methods are available in the \texttt{spatstat}
package~\parencite{spatstat} for R~\parencite{baser}. The \texttt{spatstat}
function \texttt{ppm} implements these methods using the base R \texttt{glm}
function to maximize the likelihood; I will use the Berman and Turner method
because it is the default in \texttt{ppm} and therefore better reflects the
experience of a na\"{i}ve practitioner who is not an expert on spatial point
processes.


\section{Simple Examples}

log-linear example from HW4

simulate from
\begin{equation*}
\log(\lambda(x,y)) = 5x + 2y; \quad (x, y) \in (0, 1)^{2}
\end{equation*}
but do not observe any events in \((0.5, 0.8)^{2}\). Then fit
\begin{equation*}
\log(\lambda(x,y)) = \beta_{0} + \beta_{1}x + \beta_{2}y
\end{equation*}
and predict on \((-0.5, 1.5)^{2}\).

<<hw4_sim>>=
simulate_win <- owin(c(0, 1), c(0, 1))
observe_win <- setminus.owin(simulate_win, owin(c(0.5, 0.8), c(0.5, 0.8)))
predict_win <- owin(c(-0.5, 1.5), c(-0.5, 1.5))
hw4 <- rpoispp(function(x, y){exp(5 * x + 2 * y)}, win = simulate_win)
@

<<hw4_plot, fig.cap = 'One realization of a Poisson process with log-linear intensity on the unit square.'>>=
par(mar = c(0, 0, 1, 0))
plot(hw4, main = 'Event Locations')
@

<<hw4_fit_all>>=
hw4_fit_a <- ppm(hw4 ~ x + y, correction = 'isotropic')
hw4_pred_a <- predict(hw4_fit_a, window = predict_win, se = TRUE)
# By default predictions are on a 128 by 128 grid.
@
<<hw4_fit_unobserved>>=
hw4_fit_u <- ppm(hw4[observe_win] ~ x + y, correction = 'isotropic')
hw4_pred_u <- predict(hw4_fit_u, window = predict_win, se = TRUE)
@

<<hw4_fitcoefs_a, results = 'asis'>>=
hw4_coef_a <- summary(hw4_fit_a)$coefs.SE.CI[,c('Estimate', 'S.E.')]
rownames(hw4_coef_a) <- c('\\(\\widehat{\\beta_{0}}\\)',
                          '\\(\\widehat{\\beta_{1}}\\)',
                          '\\(\\widehat{\\beta_{2}}\\)')
xtable(hw4_coef_a, label = 'hw4esta',
       caption = 'Estimated coefficients for the log-linear trend model fit using the full region.')
@

<<hw4_fitcoefs_u, results = 'asis'>>=
hw4_coef_u <- summary(hw4_fit_u)$coefs.SE.CI[,c('Estimate', 'S.E.')]
rownames(hw4_coef_u) <- c('\\(\\widehat{\\beta_{0}}\\)',
                          '\\(\\widehat{\\beta_{1}}\\)',
                          '\\(\\widehat{\\beta_{2}}\\)')
xtable(hw4_coef_u, label = 'hw4estu',
       caption = 'Estimated coefficients for the log-linear trend model fit using a subset of the region.')
@

<<hw4_fitplot, fig.pos = 'p', fig.height = 8, fig.cap = 'Estimated log-intensity surface, log-scale prediction standard errors, and prediction coeffiecient of variation from models fit using all events in the full simulation region (left) and events in a subset of the simulation region (right). The regions and event locations are overlaid in white.'>>=
par(mfrow = c(3, 2), mar = c(0, 0, 1.2, 2), las = 2, cex = 1)

plot(log(hw4_pred_a$estimate), zlim = c(-4.5, 10.5),
     main = expression(log(hat(lambda)[f](italic(list(x,y))))))
plot(simulate_win, add = TRUE, border = '#ffffff40')
points(hw4, pch = '.', col = 'white')

plot(log(hw4_pred_u$estimate), zlim = c(-4.5, 10.5),
     main = expression(log(hat(lambda)[s](italic(list(x,y))))))
plot(observe_win, add = TRUE, border = '#ffffff40')
points(hw4[observe_win], pch = '.', col = 'white')

plot(log(hw4_pred_a$se), zlim = c(-4.5, 10.5),
     main = expression(log(SE(hat(lambda)[f](italic(list(x,y)))))))
plot(simulate_win, add = TRUE, border = '#ffffff40')
points(hw4, pch = '.', col = 'white')

plot(log(hw4_pred_u$se), zlim = c(-4.5, 10.5),
     main = expression(log(SE(hat(lambda)[s](italic(list(x,y)))))))
plot(observe_win, add = TRUE, border = '#ffffff40')
points(hw4[observe_win], pch = '.', col = 'white')

plot(hw4_pred_a$se/hw4_pred_a$estimate, zlim = c(0, 1),
     main = expression(SE(hat(lambda)[f](italic(list(x,y)))) /
                         hat(lambda)[f](italic(list(x,y)))))
plot(simulate_win, add = TRUE, border = '#ffffff40')
points(hw4, pch = '.', col = 'white')

plot(hw4_pred_u$se/hw4_pred_u$estimate, zlim = c(0, 1),
     main = expression(SE(hat(lambda)[s](italic(list(x,y)))) /
                         hat(lambda)[s](italic(list(x,y)))))
plot(observe_win, add = TRUE, border = '#ffffff40')
points(hw4[observe_win], pch = '.', col = 'white')
@

easy site, realization 2,000, 390 ft spacing

use \texttt{polynom()} not \texttt{poly()}!


\section{Simulation Study}

What to compare? MSPE for this method vs the moving average kriging? I'd
like to cross-validate (could leave one transect out) but I don't know how to
contruct a criterion. Maybe compare modeled intensity within the rectangle to
a kernel intensity estimate?


\section{Discussion and Conclusion}

smallish SEs outside observed region because of faith in the model form --
need model checking

how much of the region do you need to observe to trust your model?


\appendix
\section{R Code Appendix}


\printbibliography

\end{document}
